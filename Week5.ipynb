{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQlnxKD5NrPudRkMXyV/zt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoaibanwar13/Developer_Hub_Internship_tasks/blob/master/Week5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "TS7cm5ZVCJfo",
        "outputId": "466699e0-d01b-48f3-f199-531e26e2fdbc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Vamsi/T5_Paraphrase_Pack is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/Vamsi/T5_Paraphrase_Pack/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1241\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1753\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1675\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-672115c0-536a5456514956fb30af39ab;8da79b8f-63de-49b3-a649-568f2055c9aa)\n\nRepository Not Found for url: https://huggingface.co/Vamsi/T5_Paraphrase_Pack/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d98a01065c5a>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moriginal_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The utilization of advanced technology has significantly enhanced the efficiency of modern-day operations.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mparaphrased_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparaphrase_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Text: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d98a01065c5a>\u001b[0m in \u001b[0;36mparaphrase_text\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparaphrase_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Load the model for paraphrasing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mparaphraser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text2text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Vamsi/T5_Paraphrase_Pack\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Generate paraphrased text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    769\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m         ) from e\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Vamsi/T5_Paraphrase_Pack is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def paraphrase_text(input_text):\n",
        "    # Load the model for paraphrasing\n",
        "    paraphraser = pipeline(\"text2text-generation\", model=\"Vamsi/T5_Paraphrase_Pack\")\n",
        "\n",
        "    # Generate paraphrased text\n",
        "    paraphrased = paraphraser(input_text, max_length=100, num_return_sequences=1)\n",
        "\n",
        "    return paraphrased[0]['generated_text']\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    original_text = \"The utilization of advanced technology has significantly enhanced the efficiency of modern-day operations.\"\n",
        "    paraphrased_result = paraphrase_text(original_text)\n",
        "\n",
        "    print(\"Original Text: \", original_text)\n",
        "    print(\"Paraphrased Text: \", paraphrased_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install language_tool_python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTrkZFofDvFS",
        "outputId": "c43f54b4-a0d5-4440-a773-d29bcc7814bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting language_tool_python\n",
            "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (4.66.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2024.8.30)\n",
            "Downloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: language_tool_python\n",
            "Successfully installed language_tool_python-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "\n",
        "# Download NLTK resources if not already done\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the paraphrasing model\n",
        "paraphrase_pipeline = pipeline(\"text2text-generation\", model=\"t5-base\")\n",
        "\n",
        "# Helper function to get a synonym based on word type\n",
        "def get_synonym(word, pos):\n",
        "    synonyms = wordnet.synsets(word, pos=pos)\n",
        "    if synonyms:\n",
        "        for syn in synonyms:\n",
        "            for lemma in syn.lemmas():\n",
        "                # Ensure the synonym is not the same word\n",
        "                if lemma.name().lower() != word.lower():\n",
        "                    return lemma.name().replace(\"_\", \" \")\n",
        "    return word\n",
        "\n",
        "# Map POS tags to WordNet tags\n",
        "def pos_to_wordnet(pos_tag):\n",
        "    if pos_tag.startswith(\"J\"):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith(\"V\"):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith(\"N\"):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith(\"R\"):\n",
        "        return wordnet.ADV\n",
        "    return None\n",
        "\n",
        "# Function to handle pluralization and singularization correctly\n",
        "def pluralize(word):\n",
        "    if word.endswith('y'):\n",
        "        return word[:-1] + 'ies'  # Change 'y' to 'ies'\n",
        "    elif word.endswith('s'):\n",
        "        return word  # Already plural\n",
        "    else:\n",
        "        return word + 's'  # Regular pluralization\n",
        "\n",
        "def singularize(word):\n",
        "    if word.endswith('ies'):\n",
        "        return word[:-3] + 'y'  # Change 'ies' to 'y'\n",
        "    elif word.endswith('s'):\n",
        "        return word[:-1]  # Regular singularization\n",
        "    else:\n",
        "        return word  # Already singular\n",
        "\n",
        "# Function to correct common spelling errors\n",
        "def correct_spelling(word):\n",
        "    if word == \"productivenes\":\n",
        "        return \"productiveness\"\n",
        "    return word\n",
        "\n",
        "# Function to replace selected words with synonyms, considering singular/plural\n",
        "def replace_selected_synonyms(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    result = []\n",
        "\n",
        "    for word, pos in pos_tags:\n",
        "        wordnet_pos = pos_to_wordnet(pos)\n",
        "\n",
        "        # Exclude articles, auxiliary verbs, and determiners from replacement\n",
        "        if word.lower() in {\"a\", \"an\", \"the\", \"is\", \"has\", \"have\", \"was\", \"were\", \"be\"}:\n",
        "            result.append(word)\n",
        "        elif wordnet_pos in {wordnet.ADJ, wordnet.NOUN}:\n",
        "            # Get synonym\n",
        "            synonym = get_synonym(word, wordnet_pos)\n",
        "            if synonym != word:\n",
        "                # Adjust for pluralization\n",
        "                if word.endswith('s'):\n",
        "                    synonym = pluralize(synonym)  # Ensure the synonym is plural\n",
        "                else:\n",
        "                    synonym = singularize(synonym)  # Ensure the synonym is singular\n",
        "                result.append(synonym)\n",
        "            else:\n",
        "                result.append(word)\n",
        "        else:\n",
        "            result.append(word)\n",
        "\n",
        "    # Correct common spelling mistakes\n",
        "    result = [correct_spelling(word) for word in result]\n",
        "\n",
        "    # Join words and handle punctuation correctly\n",
        "    humanized_text = []\n",
        "    for token in result:\n",
        "        # If the token is punctuation, add it without a leading space\n",
        "        if token in string.punctuation:\n",
        "            if humanized_text:\n",
        "                humanized_text[-1] += token\n",
        "        else:\n",
        "            humanized_text.append(token)\n",
        "\n",
        "    # Capitalize the first letter of the first word in the sentence\n",
        "    if humanized_text:\n",
        "        humanized_text[0] = humanized_text[0].capitalize()\n",
        "\n",
        "    return \" \".join(humanized_text)\n",
        "\n",
        "# Original AI-generated text\n",
        "original_text = (\"\"\"Artificial intelligence (AI) is revolutionizing various aspects of both business and personal life, profoundly influencing how we operate in today's modern world. As AI systems advance, their applications span diverse industries, enhancing productivity and refining decision-making processes. In the corporate realm, AI tools streamline operational workflows by automating routine tasks, allowing employees to focus on more strategic endeavors. For instance, AI-powered chatbots provide customer service support around the clock, efficiently handling inquiries and significantly reducing response times. Furthermore, AI algorithms analyze vast amounts of data to extract insights that guide strategic planning and marketing initiatives, ultimately leading to more informed decisions and improved customer experiences. However, the integration of AI technology comes with challenges, including concerns regarding data privacy and ethical implications. Therefore, businesses must prioritize responsible AI practices, ensuring transparency and fairness in their applications. Balancing innovation with ethical considerations is essential for harnessing the full potential of AI while addressing the challenges it poses. As AI continues to evolve, it will undoubtedly shape the future landscape of our society, creating new opportunities and transforming the way we interact with technology in our daily lives.\"\"\")\n",
        "\n",
        "# Step 1: Use paraphrasing to ensure grammatical flow\n",
        "try:\n",
        "    # Paraphrased Text with minimal synonym changes\n",
        "    paraphrased_text = original_text  # Here, no paraphrasing is applied, but you can add if needed\n",
        "\n",
        "    # Step 2: Apply synonym replacement with exclusions\n",
        "    humanized_text = replace_selected_synonyms(paraphrased_text)\n",
        "\n",
        "    print(\"Original Text:\", original_text)\n",
        "    print(\"Paraphrased Text:\", paraphrased_text)\n",
        "    print(\"Humanized Text:\", humanized_text)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"An error occurred during processing:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqKo22V3nHDG",
        "outputId": "e14e811d-409d-4769-ea69-a6cd743d1eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Artificial intelligence (AI) is revolutionizing various aspects of both business and personal life, profoundly influencing how we operate in today's modern world. As AI systems advance, their applications span diverse industries, enhancing productivity and refining decision-making processes. In the corporate realm, AI tools streamline operational workflows by automating routine tasks, allowing employees to focus on more strategic endeavors. For instance, AI-powered chatbots provide customer service support around the clock, efficiently handling inquiries and significantly reducing response times. Furthermore, AI algorithms analyze vast amounts of data to extract insights that guide strategic planning and marketing initiatives, ultimately leading to more informed decisions and improved customer experiences. However, the integration of AI technology comes with challenges, including concerns regarding data privacy and ethical implications. Therefore, businesses must prioritize responsible AI practices, ensuring transparency and fairness in their applications. Balancing innovation with ethical considerations is essential for harnessing the full potential of AI while addressing the challenges it poses. As AI continues to evolve, it will undoubtedly shape the future landscape of our society, creating new opportunities and transforming the way we interact with technology in our daily lives.\n",
            "Paraphrased Text: Artificial intelligence (AI) is revolutionizing various aspects of both business and personal life, profoundly influencing how we operate in today's modern world. As AI systems advance, their applications span diverse industries, enhancing productivity and refining decision-making processes. In the corporate realm, AI tools streamline operational workflows by automating routine tasks, allowing employees to focus on more strategic endeavors. For instance, AI-powered chatbots provide customer service support around the clock, efficiently handling inquiries and significantly reducing response times. Furthermore, AI algorithms analyze vast amounts of data to extract insights that guide strategic planning and marketing initiatives, ultimately leading to more informed decisions and improved customer experiences. However, the integration of AI technology comes with challenges, including concerns regarding data privacy and ethical implications. Therefore, businesses must prioritize responsible AI practices, ensuring transparency and fairness in their applications. Balancing innovation with ethical considerations is essential for harnessing the full potential of AI while addressing the challenges it poses. As AI continues to evolve, it will undoubtedly shape the future landscape of our society, creating new opportunities and transforming the way we interact with technology in our daily lives.\n",
            "Humanized Text: Unreal intelligence service( Army Intelligence) is revolutionizing assorteds aspects of both concerns and personal living, profoundly influencing how we operate in today 's mod universe. As Army Intelligence systems progres, their applications span diver industries, enhancing productiveness and refining decision-making procedures. In the bodied kingdom, Army Intelligence tools streamline functional work flows by automating everyday undertakings, allowing employees to focus on more than strategical enterprises. For case, AI-powered chatbots provide client religious service reinforcement around the clock, efficiently handling inquiries and significantly reducing reaction multiplications. Furthermore, Army Intelligence algorithms analyze huge sums of information to extract penetrations that guide strategical preparation and selling enterprises, ultimately leading to more informed decisions and improved client experiences. However, the integrating of Army Intelligence engineering comes with challenges, including concerns regarding information privatenes and honorable deductions. Therefore, business must prioritize responsible for Army Intelligence practices, ensuring transparence and equities in their applications. Balancing invention with honorable considerations is indispensable for harnessing the entire potentiality of Army Intelligence while addressing the challenges it poses. As Army Intelligence continues to evolve, it will undoubtedly shape the hereafter landscape painting of our club, creating fresh opportunities and transforming the manner we interact with engineering in our day-to-day lifes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import uuid\n",
        "from google.colab import files\n",
        "\n",
        "# Create directories for saving original and augmented images\n",
        "original_folder = 'images/original'\n",
        "augmented_folder = 'images/augmented'\n",
        "os.makedirs(original_folder, exist_ok=True)\n",
        "os.makedirs(augmented_folder, exist_ok=True)\n",
        "\n",
        "# Step 1: Load, resize, convert, and save original image with a unique name\n",
        "def load_and_save_image(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")  # Convert image to RGB mode\n",
        "    img = img.resize((224, 224))  # Resize to 224x224 pixels\n",
        "    img = np.array(img) / 255.0   # Normalize pixel values between 0 and 1\n",
        "\n",
        "    # Save the original image with a unique name\n",
        "    unique_name = f\"original_{uuid.uuid4().hex}.jpg\"\n",
        "    original_save_path = os.path.join(original_folder, unique_name)\n",
        "    Image.fromarray((img * 255).astype(np.uint8)).save(original_save_path)\n",
        "\n",
        "    return img\n",
        "\n",
        "# Step 2: Image augmentation and saving\n",
        "def augment_and_save_images(image):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=45,         # Rotate images by up to 45 degrees\n",
        "        width_shift_range=0.2,     # Horizontal shift\n",
        "        height_shift_range=0.2,    # Vertical shift\n",
        "        brightness_range=[0.5, 1.5], # Adjust brightness\n",
        "        zoom_range=0.2,            # Zoom in and out\n",
        "        horizontal_flip=True,      # Flip horizontally\n",
        "        vertical_flip=True,        # Flip vertically\n",
        "        fill_mode='nearest'        # Fill pixels that go outside boundaries\n",
        "    )\n",
        "\n",
        "    # Reshape image to (1, 224, 224, 3) for the generator\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Generate and save five augmented versions\n",
        "    for i in range(5):\n",
        "        augmented_image = next(datagen.flow(image, batch_size=1))[0]\n",
        "        unique_name = f\"augmented_{uuid.uuid4().hex}.jpg\"\n",
        "        augmented_save_path = os.path.join(augmented_folder, unique_name)\n",
        "\n",
        "        # Convert to RGB and save the augmented image\n",
        "        Image.fromarray((augmented_image * 255).astype(np.uint8)).convert(\"RGB\").save(augmented_save_path)\n",
        "\n",
        "# Step 3: Upload images to Colab\n",
        "uploaded = files.upload()  # Use this to upload images from local drive\n",
        "\n",
        "# Process each uploaded image\n",
        "for image_path in uploaded.keys():\n",
        "    image = load_and_save_image(image_path)\n",
        "    augment_and_save_images(image)\n",
        "\n",
        "# Zip the 'images' folder for easy download\n",
        "!zip -r images.zip images\n",
        "\n",
        "# Download the zipped file (images.zip)\n",
        "files.download('images.zip')\n"
      ],
      "metadata": {
        "id": "HOm3gxcBn9Y5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5615344c-78b3-46fe-9eb0-d6c403d71aad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da42462c-6933-4e91-9e48-ed1125625086\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da42462c-6933-4e91-9e48-ed1125625086\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pexels-hatice-baran-153179658-27914234.jpg to pexels-hatice-baran-153179658-27914234.jpg\n",
            "Saving pexels-miami302-16114610.jpg to pexels-miami302-16114610.jpg\n",
            "Saving pexels-ozanculha-28949031.jpg to pexels-ozanculha-28949031.jpg\n",
            "Saving pexels-majesticaljasmin-10414211.jpg to pexels-majesticaljasmin-10414211.jpg\n",
            "Saving pexels-thecactusena-20474596.jpg to pexels-thecactusena-20474596.jpg\n",
            "Saving pexels-tim-diercks-719708976-28665515.jpg to pexels-tim-diercks-719708976-28665515.jpg\n",
            "Saving pexels-freddy-photography-llc-rezvanian-2046158892-29171785.jpg to pexels-freddy-photography-llc-rezvanian-2046158892-29171785.jpg\n",
            "Saving pexels-olena-dm-2005727024-29020134.jpg to pexels-olena-dm-2005727024-29020134.jpg\n",
            "Saving pexels-hobiphotography-19300468.jpg to pexels-hobiphotography-19300468.jpg\n",
            "Saving pexels-ioanamtc-14014270.jpg to pexels-ioanamtc-14014270.jpg\n",
            "Saving pexels-susydrake-28802213.jpg to pexels-susydrake-28802213.jpg\n",
            "updating: images/ (stored 0%)\n",
            "updating: images/augmented/ (stored 0%)\n",
            "updating: images/augmented/augmented_9939d3e9a1b4462fa447cf2856b1c6f0.jpg (deflated 3%)\n",
            "updating: images/augmented/augmented_98aff39f192240eba8760a87ddf7d5b6.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_787833c828fd43689e3388eda7e87b9c.jpg (deflated 6%)\n",
            "updating: images/augmented/augmented_4c5e8d3f08bf483fb73cafedadccb32f.jpg (deflated 4%)\n",
            "updating: images/augmented/augmented_9e3878477a694b2c9f8019b4932188ae.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_6e6bca9913f944b38c985edc34e3e40e.jpg (deflated 9%)\n",
            "updating: images/augmented/augmented_bd699f8e901b4b69984c01263f2ffd24.jpg (deflated 4%)\n",
            "updating: images/augmented/augmented_a43f8dd18f214ed6a8c6945dfa046f6e.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_f11d6f6be08e4313a8c8573a4a8294bf.jpg (deflated 4%)\n",
            "updating: images/augmented/augmented_80eaf1e1a15a4d22a455ae22dce549cb.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_da9973f95c3e473d9fa6518bd14496ed.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_488ec742c2784201a1067f0c0edf252f.jpg (deflated 12%)\n",
            "updating: images/augmented/augmented_66b552c1aa5f4fc4a52c6fb92b586770.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_bee4186b5dcf4e22950cc719f528e707.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_a495e0320a8349c19a6c7637ac42310b.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_9c919391880d4538987bcf94dc36991c.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_2ff37b3bc5e145f19eda2f22e383a6b5.jpg (deflated 7%)\n",
            "updating: images/augmented/augmented_04eb0dc088354d688d526ffc8afef52a.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_e75e551b4537428bae23022c57d21658.jpg (deflated 6%)\n",
            "updating: images/augmented/augmented_ca8f22caeee9434dbb5f2d41e045e958.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_5c6926c3f24742a18bea4d49ba3f665a.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_230cbb188fb1442e9c97254ad03067b4.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_b43f87cd399e44769014fe8f56e0f4f9.jpg (deflated 6%)\n",
            "updating: images/augmented/augmented_32fce82838934ed2a7dce7f6e3fad647.jpg (deflated 13%)\n",
            "updating: images/augmented/augmented_34d1ed74295043f2ac4d861f1ea4a20d.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_33d58e0473524cc8afde81ce54ef7ebc.jpg (deflated 3%)\n",
            "updating: images/augmented/augmented_53f75f5e6bd9440ca590af541bfe3b98.jpg (deflated 68%)\n",
            "updating: images/augmented/augmented_95cef5952bdb44d58cbb3062026e98e4.jpg (deflated 5%)\n",
            "updating: images/augmented/augmented_a01b96389f4b465996ade1194538af58.jpg (deflated 18%)\n",
            "updating: images/augmented/augmented_5dcc07dc4008495ba176e183fab41f2a.jpg (deflated 68%)\n",
            "updating: images/original/ (stored 0%)\n",
            "updating: images/original/original_5d17cb9d479542cd98cd4bf8b596bf67.jpg (deflated 7%)\n",
            "updating: images/original/original_9c86d0134fec43ca8c74bcc328913cdb.jpg (deflated 9%)\n",
            "updating: images/original/original_c708797f686c4d28a2497dda2c9fbc42.jpg (deflated 21%)\n",
            "updating: images/original/original_f5abc3c1974c47a0b31b51e5fbf2d8ce.jpg (deflated 25%)\n",
            "updating: images/original/original_ea05591728234239a76df7ce259a2c16.jpg (deflated 15%)\n",
            "updating: images/original/original_d2813a7a4b6e4285b10b34a40bbab1b9.jpg (deflated 6%)\n",
            "  adding: images/augmented/augmented_7613e0a9334848c8817904cc101aea84.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_6c4cf3f9c03c443b821a2ee79a1344f6.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_f193867c058045aba5af61c265801256.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_42cb2dd173b1469a9c4eece411585745.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_bcac36e5102f4c2db891b4aa8cb1b911.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_da1e8adc2e674130abec3662d965d9bb.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_228b954a227442a29332fdc4362dd306.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_6bd9c7db19ca44cfa2c32f7f46473013.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_981de5ada0274804a57fad5fb0a59c99.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_07955655eed3441eb3fda9ca518a5e8b.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_59de27f60cce42268d84f187e6a32cc6.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_05227b28482d4c25bf0195b10469caed.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_0b57a96e851542afa9ec2639252db942.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_2e16abf542534d57b237ed5979eb5b3e.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_4c4219e3646a4a53a9898715dfeceb79.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_b5ac0759a07949ec813c1dd37bcb119d.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_f9c864feccc84669bfaae63009a75cc4.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_01b034fba3504ec1986e7c581cbc234d.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_36d55c50432748fc857577d457e75e77.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_4b3d3cd0cc954bf78ff7bba9b93cf7cb.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_172f102a12394f9996d6cf61f0a3004f.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_c3d491a5881f43adb7a4f890a38639b4.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_e92b56ab0ac945399d7cabaf72372cc7.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_680b6e77caba44d5b8355433fe0b1044.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_73ad0854104641b69268c05ffeb73bda.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_3b3b824aba8a40209649c1e907d7f3cc.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_25a36a30803247c3a3f2c16d8127e14a.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_a73c7d0b468e4f1f9b25c8eb11edd942.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_2080e6168164417a8da5b8303d3c9d29.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_614b4f68222f4f2cbdd15f43cec29279.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_7d35b5992f7243d1ac56820dfeb8bfda.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_335c522d02864fcc80155d73efb42d99.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_7c4e5a08f98d4c1ba27495db189e45ff.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_deab17cbf5cc469b9fdc1a2d4298d542.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_0933abf2822948688a0bcc6e9f1087d3.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_e677646655e34c1ea37ce4770540b51c.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_a9bf69383e6245c89f2e0ee89ca1218e.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_d89f85e2ec15414e96ff49d91a17ca18.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_23b9338961694b2c869b24dc518855a8.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_7747748ead594efda9e9e5a7d3ee21df.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_addebf622ce54b4c92304fe3bac1545c.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_66b7535308da47e1862735580a88e13c.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_e79471feaa1c458ea707b162443a4563.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_3cab4ab394c34cbfac8023856260ecbd.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_f6c2c440d9ea488aa27f82f0d282cf13.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_c988ed383ab6406da6fd16e114c6ca50.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_48757b8bf481476a93b49ba0d9beb32a.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_ff9a93ce47b34c9e83a5430101a986ec.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_43cd178c70064ceba22d98333d48a558.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_a7bf5b8c1c3c49cb8404f14eb1509b1a.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_04c17eba88c4483d82b8bdcf23f90f67.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_f5f1a99aab2845a28e9fbdd6d30c7dbd.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_29e84c242efc47b7a861f8ec877b770d.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_f855931d14194b9c89d4ee5537b2c0e5.jpg (deflated 68%)\n",
            "  adding: images/augmented/augmented_98e12675cfc04917a7a6a474afffe6e9.jpg (deflated 68%)\n",
            "  adding: images/original/original_c804de1c1cb04b45b1fcbb854604d383.jpg (deflated 1%)\n",
            "  adding: images/original/original_008c57b291314dd480fd998b3eadfc38.jpg (deflated 2%)\n",
            "  adding: images/original/original_ce04cab220f7445f85db84371cb5255e.jpg (deflated 2%)\n",
            "  adding: images/original/original_fa8fa971c2514c16a78e48b7dfcd4a8f.jpg (deflated 1%)\n",
            "  adding: images/original/original_687a0c95635b48e6a9f62e8943d269de.jpg (deflated 1%)\n",
            "  adding: images/original/original_240d1268df9649ae967fafa2e38f7e3e.jpg (deflated 1%)\n",
            "  adding: images/original/original_3cbb52c2608047c0bb5c29557c8b4391.jpg (deflated 1%)\n",
            "  adding: images/original/original_baee7be8f12c4273878b3d1678562a2b.jpg (deflated 1%)\n",
            "  adding: images/original/original_067136c6d07a44cb9749fb7bcb11e4cf.jpg (deflated 1%)\n",
            "  adding: images/original/original_a29bcc210ce34aa8a159d80e511114e6.jpg (deflated 1%)\n",
            "  adding: images/original/original_8292a7fa9a82421da69d595a002f24dc.jpg (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f3e76c65-aa31-4d8f-baf3-75c2011315cb\", \"images.zip\", 378766)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}